\chapter{Introdução}\label{chp:LABEL_CHP_1}

%Felipe:Mudei o estilo de citação, para incluir o nome e data, ficou melhor assim?
\emph{Support Vector Machine}, Máquina de Vetores de Suporte em português, é um método de aprendizado de máquina. Seu modelo básico descreve um classificador binário, podendo ser modificado para regressão, uma estimativa numérica, ou multi-classificação, classificação entre mais de duas classes. 
A maquina de vetores de suporte representa os dados como pontos em espaço $n$ dimensional, onde $n$ é o numero de parâmetros do conjunto de teste. A MVS cria um hiperplano que divide esse espaço de forma que seja possível identificar à qual classe o exemplo pertence. Esse hiperplano é definido atribuindo pesos a pontos desse espaço que são gerados a partir do conjunto de treinamento. Esses pontos são chamados de vetores de suporte. Nesse trabalho eu implemento
um algoritmo simples de MVS que encontra o hiperplano usando força bruta, levando em consideração todos os pontos do conjunto de treinamento e convergindo em direção ao hiperplano que melhor divide o espaço entre as duas classes. Esse algoritmo é muito custoso pois é preciso comparar todos os pares de exemplos do conjunto de treinamento a cada iteração. Como temos um conjunto grande de dados e um algoritmo custoso e repetitivo temos um caso forte para a paralelização.
\par
Para paralelização escolhi a GPU. GPUs tradicionalmente são usados para computação gráfica e foram otimizados para processar imagens e espaços com um conjunto enorme de pontos. Essa capacidade de processar uma grande quantidade de dados em paralelo tem utilidade em muitos outros campos além dá computação gráfica. 
\par
A implementação de um MVS usando GPU não é novidade na computação. Catanzaro, Sundaram e Keutzer em 2008 \cite{art:REF_ART_1} mostraram que uma Maquina de Vetores de Suporte utilizando a arquitetura paralela da GPU poderia ser muito mais rápida. Eles compararam sua performance com o LIBSVM \cite{art:LIBSVM}, uma das bibliotecas mais populares e mais completas de MVS e o ganho deles foi de 9 à 35 vezes melhor no treinamento e de 81 à 138 vezes melhor na classificação. Catanzaro et al. usou o algoritmo SMO, \emph{Sequential Minimal Optimization}, que divide o problema de otimização em problemas menores.
\par
Austin Carpenter em 2009 \cite{art:REF_ART_2} disse que a versão de Catanzaro não fazia regressão e teve uma precisão um pouco abaixo do LIBSVM em um dos conjuntos de dados pois usava float invés de double. As GPUS possuem mais unidades logicas de float do que double, o que motivou a escolha de Catanzaro por velocidade sobre precisão. O programa de Carpenter implementa regressão e usa uma mistura de float e double, recuperando a precisão perdida sem perda de velocidade.
\par
Athanasopoulos, Dimou, Mezaris, Kompatsiaris (2011)\cite{art:REF_ART_3} expandiram a LIBSVM de forma que todas as opções da biblioteca continuam disponíveis e com a mesma precisão mas com uma velocidade aumentada graças a paralelizações feitas usando GPU.\par


\section{Objetivo do Trabalho}\label{sec:LABEL_CHP_1_SEC_B}
O objetivo do trabalho é desenvolver uma maquina de vetores de suporte sequencial usando o algoritmo Kernel-Adatron, \emph{Kernel-Adatron Algorithm} descrito por Colin Campbell e Nello Cristianini \cite{art:LIVRO_KAA}. Esse algoritmo é mais simples que o SMO implementado pelos artigos referenciados anteriormente e é normalmente recomendado como uma introdução à implementação da maquina de vetores de suporte já que sua implementação é simples e continua próxima da teoria. 
%silvana: o que quer dizer "continua proximo da teoria geral"?
%Felipe: por próximo da teoria geral, ou só próximo da teoria,  quero dizer que ele é mais simples e não utiliza muitas técnicas diferentes como o Quadratic Program Solver e o SMO que usam outros conceitos matemáticos e da área de otimização
Além de sua simplicidade escolhi o Kernel-Adatron pois sua metodologia de força bruta repetitiva teria alto potencial para mostrar uma melhora em uma versão paralela.
\par
Para analisar a performance pretendo desenvolver uma versão sequencial e uma versão paralela usando CUDA. Para testar essas implementações uso os mesmos conjuntos de dados usados por Catanzaro e Carpenter em seus artigos, esses conjuntos de dados podem ser encontrados no site do LIBSVM. Minha intenção é comparar a velocidade e a precisão usando validação cruzada de 10 partições, classificando 10 conjuntos disjuntos e tirando sua média.
%silvana: o que é "validação cruzada de 10 folhas"??
%Felipe: Assim ta melhor?

\section{Organização do Texto}\label{sec:LABEL_CHP_1_SEC_C}
O restante deste texto está organizado da seguinte forma: 
\par
No capitulo \ref{chp:LABEL_CHP_2} descrevo a evolução da teoria por trás da maquina de vetores de suporte, começando com a classificação de exemplos com dois parâmetros linearmente separáveis até as perguntas mais complexas: porque é preciso escolher a maior margem possível? como é possível classificar conjuntos que não são linearmente separáveis? como lidar com exemplos imperfeitos e ruídos? Apresento algumas implementações de MVS e explico porque escolhi o Kernel-Adatron.

No capítulo \ref{chp:LABEL_CHP_3} descrevo melhor a programação paralela em GPU como funciona o modelo de SIMD, como o processamento é distribuído na placa de vídeo e alguns métodos utilizados.

No capítulo \ref{chp:LABEL_CHP_4} apresento parte do código sequencial e descrevo algumas dificuldades de implementação. Explico como é feito a analise de precisão através de validação cruzada. Em seguida explico como usei CUDA e de que forma o MVS está executando em paralelo. Por ultimo descrevo como compilar e executar o programa.

No capítulo \ref{chp:LABEL_CHP_5} descrevo os conjuntos de dados utilizados, o hardware utilizado e quais as métricas usei para análise. Em seguida apresento os resultados dos testes.

Por fim, no capítulo \ref{chp:LABEL_CHP_6} escrevo o que posso concluir dos testes e que modificações conseguiram melhorar o desempenho do programa. Para encerrar traço algumas funcionalidades que poderiam ser incluídas/experimentadas futuramente.