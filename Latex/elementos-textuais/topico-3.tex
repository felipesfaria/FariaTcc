\chapter{Programação Paralela com GPU}\label{chp:LABEL_CHP_3}

%\section{GPU, Graphics Processing Unit}

%\subsection{Programação Paralela}
Até o início dos anos 2000 o aumento na capacidade de processamento dos computadores costumava acontecer pelo aumento de frequência de processamento das CPUs. Esse aumento foi interrompido pois não era mais possível aumentar o processamento mantendo a dissipação de calor. A forma que a industria encontrou de manter o crescimento de processamento dos computadores sem poder aumentar a frequência foi através da programação paralela, os CPUs passaram a ter mais de um núcleo capaz de rodar diferentes instruções simultaneamente, assim a quantidade total de processamento continuou a crescer.

O conceito de programação paralela consiste em distribuir o processamento de um programa
%silvana: ...com a finalidade de reduzir o tempo total de processamento
. Isso pode ser feito de algumas formas. Os programas podem executar em diferentes núcleos de um mesmo computador dividindo o processamento em diferentes threads ou processos, pode ser dividido em diferentes máquinas através de um cluster ou computação em nuvem e pode ser dividido entre uma CPU e 
%silvana: ...aceleradores, como por exemplo uma GPU...
uma GPU que é o foco desse trabalho.

%\subsection{Computação Heterogênea}
%Computação heterogênea é o conceito de utilizar arquiteturas diferentes para otimizar o processamento das aplicações que executam em um nó computacional. Alguns exemplos são as GPUs (Graphics Processing Unit, unidade de processamento gráfica) e FPGAs (Field-Programmable Gate Array, Arranjo de Portas Programável em Campo). Essas arquiteturas são chamadas de aceleradores pois tem o objetivo de otimizar um tipo especifico de processamento.

O uso de arquiteturas diferentes em um programa não é trivial e geralmente exige um conhecimento aprofundado das capacidades de cada unidade de processamento. Por esse motivo isso não é feito de forma automática, o uso das arquiteturas é feito em chamadas explicitas. Não basta encaixar uma GPU ou FPGA na sua placa mãe e esperar que seu programa tire proveito desse hardware, nem é possível simplesmente dizer para um programa feito para executar em CPU executar em uma GPU. Mesmo que fosse possível, não é verdade que todo algoritmo rode melhor em um acelerador já que eles são otimizados para casos de uso específico.

\section{GPUs}
GPUs, também conhecidas como placas de vídeo, originalmente eram conhecidas como aceleradores gráficos. Seu objetivo era o de processar imagens rapidamente. Algumas das aplicações necessárias são alterar a cor de todos os pixels de uma imagem, rotação e translação de polígonos altamente complexos com centenas de pontos e aplicação de texturas e calculo de luminosidade nesses Polígonos. Fica claro ver que em muitas das aplicações necessárias para uma placa de vídeo acelerar o processamento de imagens é necessário que a mesma operação seja feita em diversos pontos. Para esse intuito as GPUs adotam um modelo altamente paralelo com centenas de unidades logicas. Inicialmente o foco principal dessas placas era na industria de jogos e esse mercado bilionário impulsionou uma rápida evolução na capacidade das GPUs.

Não demorou muito tempo para que os desenvolvedores em geral vissem que essas aplicações não são limitadas a industria de jogos. Inicialmente era muito trabalhoso aplicar a capacidade das placas de vídeo para aplicações gerais pois era necessário conhecer APIs especificas de processamento de imagem e saber traduzir os problemas de um domínio para o outro. Essa dificuldade acabou em 2006 quando a NVIDIA, líder de mercado na industria das GPUs, lançou o CUDA (Compute Unified Device Architecture), uma plataforma de computação paralela que permite que desenvolvedores usem placas de vídeo para aplicações gerais.

\section{CUDA}
Atualmente na versão 7.5 CUDA é uma arquitetura proprietária da NVIDIA feita para desenvolvedores poderem explorar o potencial das suas GPUs para aplicações gerais. 