%Meu objetivo nesse projeto é aprofundar meu conhecimento em tópicos ensinados ao longo do curso. especificamente tecnicas de programação em GPU (Graphics Processing Unit), uma forma de computação heterogenea que executa o codigo em diferentes dispositivos de execução, e técnicas de aprendizado de máquina SVM (Support Vector Machine), uma forma de aprendizado de maquina supervisionado usado para classificação. 

%Pretendo desenvolver um programa que faça o treinamento e classificação de dados de forma paralela, computada em GPU, os dados analisados serão tirados do repositório de dados UCI \footnote{UCI Machine Learning Repository \url{http://archive.ics.uci.edu/ml/index.html}}. Serão usados os mesmos dados vistos em outros trabalhos com o mesmo objetivo \footnote{Fast Support Vector Machine Training and Classification on Graphics Processors - Catanzaro, Sundaram, Keutzer - UC Berkley}. Os resultados serão comparados com uma implementação sequencial e com bibliotecas existentes que fazem treinamento e classificação usando SVM de forma sequencial (apenas em CPU) e paralela (utilizando GPU).


%silvana: começar por aqui 
%silvana: incluir definição sucinta de SVM... 
%Suport Vector Machine é um método de aprendizado de máquina supervisionado. Seu modelo é binario de forma que após o treinamento é possivel classificar um exemplo entre duas classes.
%silvana: incluir motivação para implementacao paralela de SVM..
%O SVM projeta o conjunto de dados em um hiperplano e em seguida separa esse plano deixando a maior margem possível entre as classes a serem definidas, de forma que minimize os erros na classificação. Essa projeção e separação do plano é muito custosa computacionalmente e como é aplicado sobre um conjunto grande de dados isso faz do SVM um ótimo candidato para ser paralelizado.
%silvana: performance -->> desempenho
Nesse projeto descrevo o desenvolvimento de um classificador binário utilizando um algoritmo de máquina de vetores de suporte conhecido como Kernel-Adatron Algorithm em versões sequencial e paralela. A versão paralela é executada em GPU de forma aproveitar seu modelo SIMD (Single Instruction Multiple Data). 
%silvana: incluir descrição sucinta das caracteristicas principais do algoritmo escolhido e seus parametros
Analiso no final a diferença em performance de tempo e precisão entre as diferentes versões e alterando os parâmetros do algoritmo.


%Suport Vector Machine é um método de aprendizado de máquina supervisionado. Seu modelo é binario de forma que após o treinamento é possivel classificar um exemplo entre duas classes. O SVM projeta o conjunto de dados através de uma função kernel em um hiperplano e em seguida precisa separar esse plano deixando a maior margem possível entre as classes a serem definidas, de forma que minimize os erros na classificação. Essa projeção e separação do plano é muito custosa computacionalmente e como é aplicado sobre um conjunto grande de dados isso faz do SVM um ótimo candidato para ser paralelizado.
%GPUs tradicionalmente são usados para computação gráfica e foram otimizados para processar imagens e espaços com um conjunto enorme de pontos. Essa capacidade de processar uma grande quantidade de dados em paralelos tem utilidade em muitos outros campos além dá computação gráfica. Para que os desenvolvedores pudessem se aproveitar desse processamento para outros fins, os produtores de GPUs tem disponibilizados bibliotecas para executar operações direto na GPU. Como o CUDA distribuído pela NVIDIA para ser usado em suas placas gráficas, que eu pretendo usar nesse projeto.
%Os GPUs tradicionalmente são usados para processamento de imagens 2D e 3D e foram otimizadas para esse fim. Para isso possuem um alto numero de cores e uma memória compartilhada dedicada muito eficiente. Essa otimização pode ser explorada para outros fins alem da computação gráfica como é o exemplo do SVM onde podemos executar o kernel em diversos parametros do conjunto de dados em paralelo e encontrando a menor margem de diferença do plano em seguida.

%Uma MVS, ou máquina de vetores de suporte é um método de aprendizado de máquina. Seu modelo básico descreve um classificador binário, podendo ser modificado para regressão ou multi-classificação. A maquina de vetores de suporte representa os dados como pontos em espaço N dimensional, onde N é o numero de parâmetros do conjunto de teste. A MVS cria um hiperplano que divide esse espaço de forma que seja possível identificar à qual classe o exemplo pertence. Esse hiperplano é definido atribuindo pesos a pontos desse espaço que são gerados a partir do conjunto de treinamento. Esses pontos são chamados de vetores de suporte. Nesse trabalho eu desenvolvo um algoritmo simples de MVS que encontra o hiperplano com força bruta, levando em consideração todos os pontos do conjunto de treinamento e convergindo em direção ao hiperplano. Esse algoritmo é muito custoso pois é preciso comparar todos os pares de exemplos do conjunto de treinamento a cada iteração. Como temos um conjunto grande de dados, e um algoritmo custoso e repetitivo temos um caso forte para a paralelização.
%Para paralelização escolhi a GPU. GPUs tradicionalmente são usados para computação gráfica e foram otimizados para processar imagens e espaços com um conjunto enorme de pontos. Essa capacidade de processar uma grande quantidade de dados em paralelos tem utilidade em muitos outros campos além dá computação gráfica. Para que os desenvolvedores pudessem se aproveitar desse processamento para outros fins, os produtores de GPUs tem disponibilizados bibliotecas para executar operações direto na GPU. Como o CUDA distribuído pela NVIDIA para ser usado em suas placas gráficas, que eu pretendo usar nesse projeto.